{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees and Random Forests - classification/regression predictive\n",
    "\n",
    "* Useful with non linear problems (you cant use SVM to linearly divide the space into 2 areas)\n",
    "* Binary tree , Each root node represents a single input variable (x) and a split point on that variable (assuming the variable is numeric).\n",
    "* The leaf nodes of the tree contain an output variable (y) which is used to make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>credit.policy</th>\n",
       "      <th>int.rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>log.annual.inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico</th>\n",
       "      <th>days.with.cr.line</th>\n",
       "      <th>revol.bal</th>\n",
       "      <th>revol.util</th>\n",
       "      <th>inq.last.6mths</th>\n",
       "      <th>delinq.2yrs</th>\n",
       "      <th>pub.rec</th>\n",
       "      <th>not.fully.paid</th>\n",
       "      <th>purpose_credit_card</th>\n",
       "      <th>purpose_debt_consolidation</th>\n",
       "      <th>purpose_educational</th>\n",
       "      <th>purpose_home_improvement</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_small_business</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>829.1</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>19.48</td>\n",
       "      <td>737</td>\n",
       "      <td>5639.958333</td>\n",
       "      <td>28854</td>\n",
       "      <td>52.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  credit.policy  int.rate  installment  log.annual.inc    dti  \\\n",
       "0           0              1    0.1189        829.1       11.350407  19.48   \n",
       "\n",
       "   fico  days.with.cr.line  revol.bal  revol.util  inq.last.6mths  \\\n",
       "0   737        5639.958333      28854        52.1               0   \n",
       "\n",
       "   delinq.2yrs  pub.rec  not.fully.paid  purpose_credit_card  \\\n",
       "0            0        0               0                    0   \n",
       "\n",
       "   purpose_debt_consolidation  purpose_educational  purpose_home_improvement  \\\n",
       "0                           1                    0                         0   \n",
       "\n",
       "   purpose_major_purchase  purpose_small_business  \n",
       "0                       0                       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../Datasets/loan_data.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to - X(Train), Y(Test) \n",
    "Create an X array that contains the features to train on, and a y array with the target variable - the Price column.\n",
    "While we remove any non valuable data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use sklearn.model_selection.train_test_split to split the data (train/test) <br>\n",
    "We split the data to 70% and 30% , run the model on 70% data, and then test on the 30% and see if the results are close to the real values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('not.fully.paid',axis=1)\n",
    "y = df['not.fully.paid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model\n",
    "Create an instance of DecisionTreeClassifier() called dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information about the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "Predict the test set, and than check it to decide if the model is good.<br>\n",
    "The function predicts a value, and makes it to be between 0 and 1. <br>\n",
    "`Y < 0.5` => 0<br>\n",
    "`Y > 0.5` => 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score - a math mathod (A precent of 100) <br>\n",
    "**Be Carful!** when the score is 99% it can be a lie - because it will say only false, and never true.<br>\n",
    "It happens in situations when most of the dataset is false and just a litlle is true.<br>\n",
    "Like:<br>\n",
    "* Should I give a costumer a premium account\n",
    "* Should I send a person toa rare check\n",
    "* Will the costumerwill buy a really expencive product<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7376478775226165"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## confusion_matrix\n",
    "Because of the score problem, we use a confusion_matrix.<br>\n",
    "When there aren't numbers on the right column it means that the model never said False.<br>\n",
    "We want to see numbers only on the main diagonal, and that the rest eill be zeros.\n",
    "# TN&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FP  \n",
    "**True Negative**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "**False Positive**<br>\n",
    "(The model said 0 and it's TRUE)&nbsp;&nbsp;&nbsp;&nbsp;(The model said 1 and it's FALSE)\n",
    "\n",
    "# FN&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TP\n",
    "**False Negative**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "**True Positive**<br>\n",
    "(The model said 0 and it's FALSE)&nbsp;&nbsp;&nbsp;&nbsp;(The model said 0 and it's TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2011,  420],\n",
       "       [ 334,  109]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as skmet\n",
    "skmet.confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accurancy** - (TN +TP)/TOTAL | Like the score, it's good when the False and True values in the dataseet are equal.<br>\n",
    "**Recall**/Positive rate/Sensitivity - TP / (FN + TP) | The precent of the trues it found of all of the trues (How many sick people it recognised of all the sick people- 100% is necessary. How many spam mails it recognised of all the spam mails- 100% isn't necessary)<br>\n",
    "**Precision** - TP / (FP + TP) | Actual yes / Total perdicted yes<br>\n",
    "The precent of the real trues it found of all of the trues it found (How many sick people it recognised that are really sick - 100% is not necessary. How many spam mails it recognised hat are real spam - 100% is necessary)<br>\n",
    "**F1-score** - 2*((Precision*Recall)/(Precision + Recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      2431\n",
      "           1       0.20      0.26      0.23       443\n",
      "\n",
      "    accuracy                           0.73      2874\n",
      "   macro avg       0.53      0.54      0.53      2874\n",
      "weighted avg       0.76      0.73      0.74      2874\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(skmet.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "To improve performance, we can use many trees with a random sample of features chosen as the split.<br>\n",
    "A new random sample of features is chosen for every single tree at every single split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit model<br>\n",
    "`Overfit model`/`Too complicated model`<br>\n",
    "A situation when the model is too spesific to our train data. We trained it on too many features.<br>\n",
    "The result is that the prediction of the train data is perfect, while the prediction of the test data isn't good.<br><br>\n",
    "`Underfit model`/`Too simple model`<br>\n",
    "A situation when the model is too simple and can't predict good enugh the train data and the test data.<br><br>\n",
    "n_estimators=5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 81.5% score (Underfit)<br>\n",
    "n_estimators=50&nbsp;&nbsp;&nbsp;=> 84.9% score (Perfect)<br>\n",
    "n_estimators=100 => 84.4% score (Overfit)<br>\n",
    "\n",
    "**Tips:**\n",
    "* Always start with simpler models, and add complexity gradually, and only if it is really needed.\n",
    "* If two models seem to perform equally well, choose the simpler one.<br>\n",
    "<img src=\"img/overfit.jpg\" style=\"width:50%; float:left;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=50)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8493389004871259"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2420,   11],\n",
       "       [ 422,   21]], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skmet.confusion_matrix(y_test,rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92      2431\n",
      "           1       0.52      0.03      0.06       443\n",
      "\n",
      "    accuracy                           0.85      2874\n",
      "   macro avg       0.68      0.51      0.49      2874\n",
      "weighted avg       0.80      0.85      0.78      2874\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(skmet.classification_report(y_test,rfc_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
