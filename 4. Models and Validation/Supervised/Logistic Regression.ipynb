{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression model/Sigmoid/Binary classification\n",
    "### To answer a Boolean question â€“ Yes/No | 0/1 | True/False\n",
    "Also works with multiclass problems (Not reccomenfded). The model will do 1 VS ALL <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>rec</th>\n",
       "      <th>elen</th>\n",
       "      <th>attch</th>\n",
       "      <th>slen</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eli302@outlook.com</td>\n",
       "      <td>10</td>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                email  rec  elen  attch  slen  spam\n",
       "0  eli302@outlook.com   10   235      1    35     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../Datasets/emails.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to - X(Train), Y(Test) \n",
    "Create an X array that contains the features to train on, and a y array with the target variable - the Price column.\n",
    "While we remove any non valuable data.\n",
    "### Use sklearn.model_selection.train_test_split to split the data (train/test)\n",
    "We split the data to 70% and 30% , run the model on 70% data, and then test on the 30% and see if the results are close to the real values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['email','spam'],axis=1), \n",
    "                                                    df['spam'], test_size=0.30, \n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "We send it the X and the Y and it findes the A , B (from Y = AX + B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lanyado\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information about the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the model coefficient/weiht. (The A from Y = AX + B).<br><br>\n",
    "If one of the coefs is really small we can delete his feature from the dataset, and retrain the model.<br>\n",
    "But, first have to check that this column doesn't have big numbers (like a salary), and than it's fine that it's coef is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24287163,  0.00444749, -0.02290707,  0.05551722]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the model intercept/bias (The B from Y = AX + B).<br>\n",
    "The minimum value of every y (In this exmple, the minimum cose of every house)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.02153134])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "Predict the test set, and than check it to decide if the model is good.<br>\n",
    "The function takes the value and outputs it to be between 0 and 1. <br>\n",
    "`Y < 0.5` => 0<br>\n",
    "`Y > 0.5` => 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score \n",
    "A Math mathod (A precent of 100) <br>\n",
    "**Be Carful!** when the score is 99% it can be a lie - because it will say only false, and never true.<br>\n",
    "It happens in situations when most of the dataset is false and just a litlle is true.<br>\n",
    "Like:<br>\n",
    "* Should I give a costumer a premium account\n",
    "* Should I send a person toa rare check\n",
    "* Will the costumerwill buy a really expencive product<br><br>\n",
    "**Solutions:**\n",
    "* Try another model.<br>\n",
    "* `Undersampling`/`Oversampling` - packages in pypi, that multiply the amount of the true to the amount we want.\n",
    "https://www.kaggle.com/residentmario/undersampling-and-oversampling-imbalanced-data<br>\n",
    "https://medium.com/anomaly-detection-with-python-and-r/sampling-techniques-for-extremely-imbalanced-data-part-i-under-sampling-a8dbc3d8d6d8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8699029126213592"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion_matrix\n",
    "Because of the score problem, we use a confusion_matrix.<br>\n",
    "When there aren't numbers on the right column it means that the model never said False.<br>\n",
    "We want to see numbers only on the main diagonal, and that the rest eill be zeros.\n",
    "# TN&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FP  \n",
    "**True Negative**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "**False Positive**<br>\n",
    "(The model said 0 and it's TRUE)&nbsp;&nbsp;&nbsp;&nbsp;(The model said 1 and it's FALSE)\n",
    "\n",
    "# FN&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TP\n",
    "**False Negative**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "**True Positive**<br>\n",
    "(The model said 0 and it's FALSE)&nbsp;&nbsp;&nbsp;&nbsp;(The model said 0 and it's TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[367,   0],\n",
       "       [ 67,  81]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as skmet\n",
    "skmet.confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification_report\n",
    "\n",
    "**Accurancy** - (TN +TP)/TOTAL | Like the score, it's good when the False and True values in the dataseet are equal.<br>\n",
    "**Recall**/Positive rate/Sensitivity - TP / (FN + TP) | The precent of the trues it found of all of the trues (How many sick people it recognised of all the sick people- 100% is necessary. How many spam mails it recognised of all the spam mails- 100% isn't necessary)<br>\n",
    "**Precision** - TP / (FP + TP) | Actual yes / Total perdicted yes<br>\n",
    "The precent of the real trues it found of all of the trues it found (How many sick people it recognised that are really sick - 100% is not necessary. How many spam mails it recognised hat are real spam - 100% is necessary)<br>\n",
    "**F1-score** - 2*((Precision*Recall)/(Precision + Recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       367\n",
      "           1       1.00      0.55      0.71       148\n",
      "\n",
      "    accuracy                           0.87       515\n",
      "   macro avg       0.92      0.77      0.81       515\n",
      "weighted avg       0.89      0.87      0.86       515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(skmet.classification_report(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
