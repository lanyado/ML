{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer NN / Multi layer preceptron(MLP)\n",
    "\n",
    "**Points**\n",
    "\n",
    "**Advantages of the model:**\n",
    "* There is a math proof that a NN with only one hidden layer can learn anything. If the train data is good enough and it has enoug time to study.\n",
    "**Disadvantages of the model:**\n",
    "* It takes a long time to train it\n",
    "* It's hard to find the perfect structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../Datasets/mal_users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>K</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <th>P</th>\n",
       "      <th>Q</th>\n",
       "      <th>Res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.095</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.4</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A      B      C       D       E       F       G       H       I  \\\n",
       "0  17.99  10.38  122.8  1001.0  0.1184  0.2776  0.3001  0.1471  0.2419   \n",
       "\n",
       "         J      K       L      M      N       O       P       Q  Res  \n",
       "0  0.07871  1.095  0.9053  8.589  153.4  0.2654  0.4601  0.1189    0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activation function - Normalize the data**<br>\n",
    "To ease the function and get better results, er apply an activation functiion on the dataset, before give itt to the model.<br>\n",
    "It takes the values and changes them to value in a scale between 0 to 1.<br>\n",
    "It's good as long as the rates are still the same.<br>\n",
    "* MIN = 0<br>\n",
    "* MAX = 1<br>\n",
    "\n",
    "In a case we have numbers between `20(MIN)` to `80(MAX)`<br>\n",
    "* 20 = 0 | Because (0*60(MAX-MIN)) + 20(MIN) = 20<br>\n",
    "* 50 - 0.5 | Because (0.5*60(MAX-MIN)) + 20(MIN) = 50<br>\n",
    "* 80 = 1 | Because (1*60(MAX-MIN)) + 20(MIN) = 80<br>\n",
    "\n",
    "For exemple, the answer is 0.3<br>\n",
    "0.3 * 60(MAX-MIN) = 18 +20(MIN) = 38<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.DataFrame(df,columns=df.columns) # Save the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df = scaler.fit_transform(original_df.drop(['Res'],axis=1))\n",
    "df = pd.DataFrame(df2, columns=original_df.drop(['Res'],axis=1).columns) # make the transformed data to a dataframe and add the relevant columns\n",
    "df['Res'] = original_df['Res'] # Add the classification column that we didn't need to transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to - X(Train), Y(Test) \n",
    "Create an X array that contains the features to train on, and a y array with the target variable - the Price column.\n",
    "While we remove any non valuable data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use sklearn.model_selection.train_test_split to split the data (train/test) <br>\n",
    "We split the data to 70% , 20% , 10%\n",
    "1. Run the model on 70% data (Train).\n",
    "2. Test the model on the 20% (Validation) and change the hyper parameters. Until the `Train` and `Validation` datasets's predictions are perfect. \n",
    "3. Test the model on the `Test` to see if the results are close to the real values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['Res'],axis=1), df.Res, test_size=0.30, random_state=101)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hidden_layer_sizes`\n",
    "* The length of the tuple - the number of the deep learning layers\n",
    "* The tuple valuers - the number of neurons in each one. One neuron can solve only linear problems, while more can solve all the rest.\n",
    "* It's recommended that the neurons amount will decrece from layer to layer.<br>\n",
    "`max_iter` => The number of the times the model will run.<br>\n",
    "`learning_rate_init` => How much the archery's weight will be change at backprocession.<br>\n",
    "* As bigger as the learning rate, as quick as the model study. But there is a chance it won't convene.\n",
    "* As smaller as the learning rate, as bigger as the chance it will be excully convene. But it will study slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(100,50), max_iter=100, learning_rate_init=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "We send it first layer (Input/X) and the last layer (Output/Y) and it changes the archery's weight and the bias using fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lanyado\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100, 50), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information about the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the model coefficients/archery's weights.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.coefs_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the model intercepts/bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.intercepts_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "Predict the validation set, and than check it to decide if the model is good.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score\n",
    "A math mathod (A precent of 100) <br>\n",
    "**Be Carful!** when the score is 99% it can be a lie - because it will say only false, and never true.<br>\n",
    "It happens in situations when most of the dataset is false and just a litlle is true.<br>\n",
    "Like:<br>\n",
    "* Should I give a costumer a premium account\n",
    "* Should I send a person toa rare check\n",
    "* Will the costumerwill buy a really expencive product<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.957983193277311"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion_matrix\n",
    "Because of the score problem, we use a confusion_matrix.<br>\n",
    "When there aren't numbers on the right column it means that the model never said False.<br>\n",
    "We want to see numbers only on the main diagonal, and that the rest eill be zeros.\n",
    "# TN&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FP  \n",
    "**True Negative**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "**False Positive**<br>\n",
    "(The model said 0 and it's TRUE)&nbsp;&nbsp;&nbsp;&nbsp;(The model said 1 and it's FALSE)\n",
    "\n",
    "# FN&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TP\n",
    "**False Negative**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "**True Positive**<br>\n",
    "(The model said 0 and it's FALSE)&nbsp;&nbsp;&nbsp;&nbsp;(The model said 0 and it's TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38,  1],\n",
       "       [ 4, 76]], dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as skmet\n",
    "skmet.confusion_matrix(y_val,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification_report\n",
    "**Accurancy** - (TN +TP)/TOTAL | Like the score, it's good when the False and True values in the dataseet are equal.<br>\n",
    "**Recall**/Positive rate/Sensitivity - TP / (FN + TP) | The precent of the trues it found of all of the trues (How many sick people it recognised of all the sick people- 100% is necessary. How many spam mails it recognised of all the spam mails- 100% isn't necessary)<br>\n",
    "**Precision** - TP / (FP + TP) | Actual yes / Total perdicted yes<br>\n",
    "The precent of the real trues it found of all of the trues it found (How many sick people it recognised that are really sick - 100% is not necessary. How many spam mails it recognised hat are real spam - 100% is necessary)<br>\n",
    "**F1-score** - 2*((Precision*Recall)/(Precision + Recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        39\n",
      "           1       0.99      0.95      0.97        80\n",
      "\n",
      "    accuracy                           0.96       119\n",
      "   macro avg       0.95      0.96      0.95       119\n",
      "weighted avg       0.96      0.96      0.96       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(skmet.classification_report(y_val,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now __go back__ to the point where we created the model.<br>\n",
    "Change the hyper parameters until the train and validation set's prediction are perfect.<br>\n",
    "Than test the model with the train set to check for overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree , overfit model<br>\n",
    "`Overfit model`/`Too complicated model`<br>\n",
    "A situation when the model is too spesific to our train data. We trained it on too many features.<br>\n",
    "The result is that the prediction of the train data is perfect, while the prediction of the test data isn't good.<br><br>\n",
    "`Underfit model`/`Too simple model`<br>\n",
    "A situation when the model is too simple and can't predict good enugh the train data and the test data.<br><br>\n",
    "\n",
    "**Tips:**\n",
    "* Always start with simpler models, and add complexity gradually, and only if it is really needed.\n",
    "* If two models seem to perform equally well, choose the simpler one.<br>\n",
    "<img src=\"img/overfitting.png\" style=\"width:50%; float:left;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
